{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3faf33c-3347-4d14-98b2-df853340a40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>production_date</th>\n",
       "      <th>genres</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>director_name</th>\n",
       "      <th>director_professions</th>\n",
       "      <th>director_birthYear</th>\n",
       "      <th>director_deathYear</th>\n",
       "      <th>movie_averageRating</th>\n",
       "      <th>movie_numerOfVotes</th>\n",
       "      <th>approval_Index</th>\n",
       "      <th>Production budget $</th>\n",
       "      <th>Domestic gross $</th>\n",
       "      <th>Worldwide gross $</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar: The Way of Water</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>192.0</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>writer,producer,director</td>\n",
       "      <td>1954</td>\n",
       "      <td>alive</td>\n",
       "      <td>7.8</td>\n",
       "      <td>277543.0</td>\n",
       "      <td>7.061101</td>\n",
       "      <td>460000000</td>\n",
       "      <td>667830256</td>\n",
       "      <td>2265935552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1143642.0</td>\n",
       "      <td>8.489533</td>\n",
       "      <td>400000000</td>\n",
       "      <td>858373000</td>\n",
       "      <td>2794731755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pirates of the Caribbean: On Stranger Tides</td>\n",
       "      <td>2011-05-20</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>137.0</td>\n",
       "      <td>Rob Marshall</td>\n",
       "      <td>director,miscellaneous,producer</td>\n",
       "      <td>1960</td>\n",
       "      <td>alive</td>\n",
       "      <td>6.6</td>\n",
       "      <td>533763.0</td>\n",
       "      <td>6.272064</td>\n",
       "      <td>379000000</td>\n",
       "      <td>241071802</td>\n",
       "      <td>1045713802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>Action,Adventure,Sci-Fi</td>\n",
       "      <td>141.0</td>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>writer,producer,director</td>\n",
       "      <td>1964</td>\n",
       "      <td>alive</td>\n",
       "      <td>7.3</td>\n",
       "      <td>870573.0</td>\n",
       "      <td>7.214013</td>\n",
       "      <td>365000000</td>\n",
       "      <td>459005868</td>\n",
       "      <td>1395316979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>Action,Adventure,Sci-Fi</td>\n",
       "      <td>149.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1091968.0</td>\n",
       "      <td>8.460958</td>\n",
       "      <td>300000000</td>\n",
       "      <td>678815482</td>\n",
       "      <td>2048359754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   movie_title production_date  \\\n",
       "0                     Avatar: The Way of Water      2022-12-09   \n",
       "1                            Avengers: Endgame      2019-04-23   \n",
       "2  Pirates of the Caribbean: On Stranger Tides      2011-05-20   \n",
       "3                      Avengers: Age of Ultron      2015-04-22   \n",
       "4                       Avengers: Infinity War      2018-04-25   \n",
       "\n",
       "                     genres  runtime_minutes  director_name  \\\n",
       "0  Action,Adventure,Fantasy            192.0  James Cameron   \n",
       "1    Action,Adventure,Drama            181.0              -   \n",
       "2  Action,Adventure,Fantasy            137.0   Rob Marshall   \n",
       "3   Action,Adventure,Sci-Fi            141.0    Joss Whedon   \n",
       "4   Action,Adventure,Sci-Fi            149.0              -   \n",
       "\n",
       "              director_professions director_birthYear director_deathYear  \\\n",
       "0         writer,producer,director               1954              alive   \n",
       "1                                -                  -                  -   \n",
       "2  director,miscellaneous,producer               1960              alive   \n",
       "3         writer,producer,director               1964              alive   \n",
       "4                                -                  -                  -   \n",
       "\n",
       "   movie_averageRating  movie_numerOfVotes  approval_Index  \\\n",
       "0                  7.8            277543.0        7.061101   \n",
       "1                  8.4           1143642.0        8.489533   \n",
       "2                  6.6            533763.0        6.272064   \n",
       "3                  7.3            870573.0        7.214013   \n",
       "4                  8.4           1091968.0        8.460958   \n",
       "\n",
       "   Production budget $  Domestic gross $  Worldwide gross $  \n",
       "0            460000000         667830256         2265935552  \n",
       "1            400000000         858373000         2794731755  \n",
       "2            379000000         241071802         1045713802  \n",
       "3            365000000         459005868         1395316979  \n",
       "4            300000000         678815482         2048359754  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv('movie_statistic_dataset.csv')\n",
    "\n",
    "# Analizar los datos\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1678ef-9826-4655-954b-a33af5a6a806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4380 entries, 0 to 4379\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   movie_title           4380 non-null   object \n",
      " 1   production_date       4380 non-null   object \n",
      " 2   genres                4380 non-null   object \n",
      " 3   runtime_minutes       4380 non-null   float64\n",
      " 4   director_name         4380 non-null   object \n",
      " 5   director_professions  4380 non-null   object \n",
      " 6   director_birthYear    4380 non-null   object \n",
      " 7   director_deathYear    4380 non-null   object \n",
      " 8   movie_averageRating   4380 non-null   float64\n",
      " 9   movie_numerOfVotes    4380 non-null   float64\n",
      " 10  approval_Index        4380 non-null   float64\n",
      " 11  Production budget $   4380 non-null   int64  \n",
      " 12  Domestic gross $      4380 non-null   int64  \n",
      " 13  Worldwide gross $     4380 non-null   int64  \n",
      "dtypes: float64(4), int64(3), object(7)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6571bd4a-69f9-4d49-82f4-d7b08cd2f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar características y objetivo\n",
    "features = ['runtime_minutes', 'movie_averageRating', 'movie_numerOfVotes', 'approval_Index', 'Production budget $', 'Domestic gross $', 'genres']\n",
    "target = 'Worldwide gross $'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "numeric_features = ['runtime_minutes', 'movie_averageRating', 'movie_numerOfVotes', 'approval_Index', 'Production budget $', 'Domestic gross $']\n",
    "categorical_features = ['genres']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Crear y dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplicar la transformación\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ddbbb92-3470-49ed-b5d1-b5078be2e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arg/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-08-04 19:20:48.046764: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 19:20:48.047333: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 48032152574492672.0000 - mae: 111822328.0000 - val_loss: 61200127167037440.0000 - val_mae: 127529584.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54226010811400192.0000 - mae: 113307760.0000 - val_loss: 61200075627429888.0000 - val_mae: 127529496.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50663584547471360.0000 - mae: 110287216.0000 - val_loss: 61199895238803456.0000 - val_mae: 127529232.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46641244595552256.0000 - mae: 109031464.0000 - val_loss: 61199534461550592.0000 - val_mae: 127528688.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62313670452969472.0000 - mae: 117825048.0000 - val_loss: 61198937461096448.0000 - val_mae: 127527864.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45459488639025152.0000 - mae: 108922088.0000 - val_loss: 61198014043127808.0000 - val_mae: 127526568.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50331265747910656.0000 - mae: 113036768.0000 - val_loss: 61196789977448448.0000 - val_mae: 127524792.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46908915547373568.0000 - mae: 107137504.0000 - val_loss: 61195196544581632.0000 - val_mae: 127522496.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50634791086718976.0000 - mae: 110284728.0000 - val_loss: 61193109190475776.0000 - val_mae: 127519544.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49259594098147328.0000 - mae: 109003248.0000 - val_loss: 61190652469182464.0000 - val_mae: 127516016.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49248109355597824.0000 - mae: 109695680.0000 - val_loss: 61187701826650112.0000 - val_mae: 127511824.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47684513626587136.0000 - mae: 112595008.0000 - val_loss: 61184197133336576.0000 - val_mae: 127506816.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48243821447741440.0000 - mae: 108288536.0000 - val_loss: 61180262943293440.0000 - val_mae: 127501184.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46933182112595968.0000 - mae: 105681656.0000 - val_loss: 61175791882338304.0000 - val_mae: 127494800.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49361973233582080.0000 - mae: 111071976.0000 - val_loss: 61170775360536576.0000 - val_mae: 127487616.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49322717232496640.0000 - mae: 113101400.0000 - val_loss: 61165032989261824.0000 - val_mae: 127479440.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58795039970557952.0000 - mae: 113465568.0000 - val_loss: 61159015740080128.0000 - val_mae: 127470800.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52245502606966784.0000 - mae: 111293304.0000 - val_loss: 61152032123256832.0000 - val_mae: 127460824.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44754525591961600.0000 - mae: 108237328.0000 - val_loss: 61144825168134144.0000 - val_mae: 127450520.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51551637755396096.0000 - mae: 113520936.0000 - val_loss: 61136608895696896.0000 - val_mae: 127438800.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48096061687857152.0000 - mae: 110724920.0000 - val_loss: 61127860047314944.0000 - val_mae: 127426296.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48042344531886080.0000 - mae: 111577664.0000 - val_loss: 61118484133707776.0000 - val_mae: 127412904.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67393405583360000.0000 - mae: 114967944.0000 - val_loss: 61108773212651520.0000 - val_mae: 127398976.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56705383762231296.0000 - mae: 114904680.0000 - val_loss: 61098108808855552.0000 - val_mae: 127383720.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50026924365316096.0000 - mae: 110315792.0000 - val_loss: 61086933303951360.0000 - val_mae: 127367744.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48679975376650240.0000 - mae: 111986048.0000 - val_loss: 61074662582386688.0000 - val_mae: 127350192.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49511549764632576.0000 - mae: 112437920.0000 - val_loss: 61062026788601856.0000 - val_mae: 127332152.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63071912569339904.0000 - mae: 118936968.0000 - val_loss: 61048579245998080.0000 - val_mae: 127312920.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50374550428319744.0000 - mae: 110400928.0000 - val_loss: 61034354314313728.0000 - val_mae: 127292592.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53795753872588800.0000 - mae: 112817696.0000 - val_loss: 61019412123090944.0000 - val_mae: 127271240.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48175316719370240.0000 - mae: 108808888.0000 - val_loss: 61003988895531008.0000 - val_mae: 127249144.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54733289398730752.0000 - mae: 111660984.0000 - val_loss: 60987680904708096.0000 - val_mae: 127225872.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51502443199987712.0000 - mae: 112157008.0000 - val_loss: 60970750143627264.0000 - val_mae: 127201656.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49910277348524032.0000 - mae: 107875992.0000 - val_loss: 60952981863923712.0000 - val_mae: 127176248.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51869345076215808.0000 - mae: 112983352.0000 - val_loss: 60934539274354688.0000 - val_mae: 127149864.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54331143020871680.0000 - mae: 108155504.0000 - val_loss: 60915194741653504.0000 - val_mae: 127122224.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51465407696994304.0000 - mae: 111931520.0000 - val_loss: 60895592510914560.0000 - val_mae: 127094160.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48357298778669056.0000 - mae: 109815432.0000 - val_loss: 60874761919528960.0000 - val_mae: 127064384.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49979142854148096.0000 - mae: 110186248.0000 - val_loss: 60853424522002432.0000 - val_mae: 127033800.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57233557365456896.0000 - mae: 115215480.0000 - val_loss: 60831193771278336.0000 - val_mae: 127001952.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52365727331516416.0000 - mae: 109517760.0000 - val_loss: 60808018127749120.0000 - val_mae: 126968792.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46236499762479104.0000 - mae: 110126184.0000 - val_loss: 60783678548082688.0000 - val_mae: 126933968.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47162185473851392.0000 - mae: 108077240.0000 - val_loss: 60758419845414912.0000 - val_mae: 126897856.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61261652573552640.0000 - mae: 116823728.0000 - val_loss: 60733118193074176.0000 - val_mae: 126861552.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52516824280989696.0000 - mae: 110921968.0000 - val_loss: 60707279669821440.0000 - val_mae: 126824488.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49840870677020672.0000 - mae: 112484640.0000 - val_loss: 60679525591154688.0000 - val_mae: 126784720.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46400859570962432.0000 - mae: 108985744.0000 - val_loss: 60651286181183488.0000 - val_mae: 126744256.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55266067206897664.0000 - mae: 107528616.0000 - val_loss: 60621809820631040.0000 - val_mae: 126702048.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44717082067075072.0000 - mae: 107781096.0000 - val_loss: 60592384999686144.0000 - val_mae: 126659744.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52232699309457408.0000 - mae: 114782800.0000 - val_loss: 60561345271037952.0000 - val_mae: 126615272.0000\n",
      "Epoch 1/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 43371773755916288.0000 - mae: 105438424.0000 - val_loss: 61200127167037440.0000 - val_mae: 127529584.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50803995618312192.0000 - mae: 114882840.0000 - val_loss: 61200127167037440.0000 - val_mae: 127529576.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53638622494064640.0000 - mae: 115809288.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529568.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53011759132311552.0000 - mae: 112469920.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529552.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50836529995579392.0000 - mae: 109600768.0000 - val_loss: 61200114282135552.0000 - val_mae: 127529552.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58544974089682944.0000 - mae: 119091992.0000 - val_loss: 61200114282135552.0000 - val_mae: 127529536.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51502417430183936.0000 - mae: 113034256.0000 - val_loss: 61200114282135552.0000 - val_mae: 127529528.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42356722660016128.0000 - mae: 104534960.0000 - val_loss: 61200114282135552.0000 - val_mae: 127529520.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53628129888960512.0000 - mae: 111823088.0000 - val_loss: 61200114282135552.0000 - val_mae: 127529520.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51948475553677312.0000 - mae: 112596512.0000 - val_loss: 61200105692200960.0000 - val_mae: 127529504.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48998125079101440.0000 - mae: 112658840.0000 - val_loss: 61200105692200960.0000 - val_mae: 127529496.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51293870998159360.0000 - mae: 112547584.0000 - val_loss: 61200105692200960.0000 - val_mae: 127529496.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49670343295500288.0000 - mae: 112431032.0000 - val_loss: 61200101397233664.0000 - val_mae: 127529480.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45850184634073088.0000 - mae: 108209080.0000 - val_loss: 61200101397233664.0000 - val_mae: 127529472.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52326441265659904.0000 - mae: 111929456.0000 - val_loss: 61200101397233664.0000 - val_mae: 127529464.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43980830183260160.0000 - mae: 106654984.0000 - val_loss: 61200101397233664.0000 - val_mae: 127529456.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47110495542444032.0000 - mae: 105061184.0000 - val_loss: 61200097102266368.0000 - val_mae: 127529456.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55301187154477056.0000 - mae: 111415024.0000 - val_loss: 61200097102266368.0000 - val_mae: 127529456.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55216009363062784.0000 - mae: 114127648.0000 - val_loss: 61200097102266368.0000 - val_mae: 127529456.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53384364725108736.0000 - mae: 114623528.0000 - val_loss: 61200097102266368.0000 - val_mae: 127529456.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49311060691255296.0000 - mae: 110514504.0000 - val_loss: 61200097102266368.0000 - val_mae: 127529456.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59066009457262592.0000 - mae: 116677176.0000 - val_loss: 61200088512331776.0000 - val_mae: 127529440.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61754826488283136.0000 - mae: 115522880.0000 - val_loss: 61200088512331776.0000 - val_mae: 127529424.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45901543852998656.0000 - mae: 106993288.0000 - val_loss: 61200084217364480.0000 - val_mae: 127529424.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53335152989831168.0000 - mae: 110992288.0000 - val_loss: 61200084217364480.0000 - val_mae: 127529424.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56727030397403136.0000 - mae: 116321064.0000 - val_loss: 61200084217364480.0000 - val_mae: 127529408.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45185297926848512.0000 - mae: 107893736.0000 - val_loss: 61200075627429888.0000 - val_mae: 127529408.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45021883011170304.0000 - mae: 104351432.0000 - val_loss: 61200075627429888.0000 - val_mae: 127529400.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55341220544643072.0000 - mae: 114947728.0000 - val_loss: 61200075627429888.0000 - val_mae: 127529400.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46508053364736000.0000 - mae: 107545480.0000 - val_loss: 61200075627429888.0000 - val_mae: 127529392.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49812064331366400.0000 - mae: 112008560.0000 - val_loss: 61200075627429888.0000 - val_mae: 127529392.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55392678547816448.0000 - mae: 115532984.0000 - val_loss: 61200075627429888.0000 - val_mae: 127529368.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48202194624708608.0000 - mae: 108924680.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529360.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52843104356532224.0000 - mae: 118614688.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529344.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47502441372975104.0000 - mae: 107310024.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529344.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54703439376023552.0000 - mae: 109017904.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529344.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51426143105974272.0000 - mae: 110020616.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529328.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50479875911319552.0000 - mae: 110687976.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529328.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53508802812575744.0000 - mae: 111630328.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529328.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50690230524575744.0000 - mae: 112365024.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529312.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48216406671491072.0000 - mae: 110971256.0000 - val_loss: 61200071332462592.0000 - val_mae: 127529312.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48132667694120960.0000 - mae: 107861192.0000 - val_loss: 61200067037495296.0000 - val_mae: 127529296.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49425328296165376.0000 - mae: 108862432.0000 - val_loss: 61200067037495296.0000 - val_mae: 127529288.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46234609976868864.0000 - mae: 107434288.0000 - val_loss: 61200067037495296.0000 - val_mae: 127529280.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50298340528619520.0000 - mae: 111750416.0000 - val_loss: 61200067037495296.0000 - val_mae: 127529280.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50152689597677568.0000 - mae: 111726512.0000 - val_loss: 61200067037495296.0000 - val_mae: 127529272.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49687235401875456.0000 - mae: 112170528.0000 - val_loss: 61200062742528000.0000 - val_mae: 127529248.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43931120231776256.0000 - mae: 106050112.0000 - val_loss: 61200062742528000.0000 - val_mae: 127529248.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49495903198773248.0000 - mae: 111691008.0000 - val_loss: 61200062742528000.0000 - val_mae: 127529248.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48106519933222912.0000 - mae: 108831400.0000 - val_loss: 61200058447560704.0000 - val_mae: 127529224.0000\n",
      "Epoch 1/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 55279330065907712.0000 - mae: 112268352.0000 - val_loss: 61199293943382016.0000 - val_mae: 127528240.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51885962304684032.0000 - mae: 113556240.0000 - val_loss: 61180267238260736.0000 - val_mae: 127499960.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53913182573428736.0000 - mae: 109918928.0000 - val_loss: 61075379841925120.0000 - val_mae: 127347832.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56912164962697216.0000 - mae: 112887752.0000 - val_loss: 60737881311805440.0000 - val_mae: 126863576.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48074376397979648.0000 - mae: 111378336.0000 - val_loss: 59949089093058560.0000 - val_mae: 125734784.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46848644271308800.0000 - mae: 107721328.0000 - val_loss: 58604412142092288.0000 - val_mae: 123794896.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52040512407863296.0000 - mae: 111295856.0000 - val_loss: 56504667055587328.0000 - val_mae: 120774968.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48199840982630400.0000 - mae: 107150616.0000 - val_loss: 53600697932840960.0000 - val_mae: 116558632.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48302306017411072.0000 - mae: 101719432.0000 - val_loss: 49787797766144000.0000 - val_mae: 111041440.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35602274554216448.0000 - mae: 93842352.0000 - val_loss: 44977644848021504.0000 - val_mae: 104296608.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35746220383141888.0000 - mae: 88170680.0000 - val_loss: 39882722713272320.0000 - val_mae: 97306752.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37332401197678592.0000 - mae: 85931936.0000 - val_loss: 34585578485841920.0000 - val_mae: 90255320.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29405356153110528.0000 - mae: 79238424.0000 - val_loss: 29665171609747456.0000 - val_mae: 83802848.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24761768509177856.0000 - mae: 75436064.0000 - val_loss: 25271763663323136.0000 - val_mae: 78379880.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22122968519802880.0000 - mae: 70679736.0000 - val_loss: 21873609161048064.0000 - val_mae: 74619008.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19504030606688256.0000 - mae: 68511520.0000 - val_loss: 19342005112930304.0000 - val_mae: 71831704.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13721426225790976.0000 - mae: 61659856.0000 - val_loss: 17352313194676224.0000 - val_mae: 69529856.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15334630974554112.0000 - mae: 63668696.0000 - val_loss: 15798537908387840.0000 - val_mae: 67561552.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13411487427067904.0000 - mae: 61529972.0000 - val_loss: 14624827499347968.0000 - val_mae: 65847600.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13864656942661632.0000 - mae: 61440604.0000 - val_loss: 13694505370779648.0000 - val_mae: 64293932.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11788741408456704.0000 - mae: 58268232.0000 - val_loss: 12909078258909184.0000 - val_mae: 62773672.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11415510897917952.0000 - mae: 58149252.0000 - val_loss: 12243643943354368.0000 - val_mae: 61301864.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11400317451108352.0000 - mae: 56708932.0000 - val_loss: 11665926818627584.0000 - val_mae: 59874960.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9110844331786240.0000 - mae: 53073008.0000 - val_loss: 11176781583220736.0000 - val_mae: 58438728.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9689344214302720.0000 - mae: 53661600.0000 - val_loss: 10673762529705984.0000 - val_mae: 57064500.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8304281685852160.0000 - mae: 50725196.0000 - val_loss: 10251789509066752.0000 - val_mae: 55733544.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9801957183062016.0000 - mae: 51686160.0000 - val_loss: 9837777210310656.0000 - val_mae: 54468556.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8566037393965056.0000 - mae: 50730400.0000 - val_loss: 9456381966942208.0000 - val_mae: 53314256.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9027103206932480.0000 - mae: 50107884.0000 - val_loss: 9114344730132480.0000 - val_mae: 52230008.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8953972261912576.0000 - mae: 48997760.0000 - val_loss: 8818335047221248.0000 - val_mae: 51135484.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8277314123071488.0000 - mae: 47386288.0000 - val_loss: 8522438644072448.0000 - val_mae: 50093176.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8078245073256448.0000 - mae: 45474896.0000 - val_loss: 8269203077332992.0000 - val_mae: 49111568.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7839157665660928.0000 - mae: 45993028.0000 - val_loss: 8036136140144640.0000 - val_mae: 48205384.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7069163445026816.0000 - mae: 44080288.0000 - val_loss: 7811651621355520.0000 - val_mae: 47318624.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6083422816567296.0000 - mae: 42215452.0000 - val_loss: 7593386752081920.0000 - val_mae: 46588024.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5895314523291648.0000 - mae: 40852368.0000 - val_loss: 7369742973140992.0000 - val_mae: 45954776.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7806582486204416.0000 - mae: 44042948.0000 - val_loss: 7211995266809856.0000 - val_mae: 45216664.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7864551659798528.0000 - mae: 43932656.0000 - val_loss: 7053180261105664.0000 - val_mae: 44631272.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7286264378163200.0000 - mae: 42141288.0000 - val_loss: 6901185663467520.0000 - val_mae: 44086572.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5718690972565504.0000 - mae: 38930316.0000 - val_loss: 6760752044048384.0000 - val_mae: 43628528.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6120930229092352.0000 - mae: 39780588.0000 - val_loss: 6627288082808832.0000 - val_mae: 43210008.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6711101148364800.0000 - mae: 40730632.0000 - val_loss: 6509929175187456.0000 - val_mae: 42806104.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5331672006393856.0000 - mae: 37761532.0000 - val_loss: 6443739971059712.0000 - val_mae: 42287520.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6332592659890176.0000 - mae: 39479904.0000 - val_loss: 6294932239155200.0000 - val_mae: 42157228.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5078327454859264.0000 - mae: 37536864.0000 - val_loss: 6211924479967232.0000 - val_mae: 41751436.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6583801002065920.0000 - mae: 37868488.0000 - val_loss: 6123699946127360.0000 - val_mae: 41473672.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4851858661179392.0000 - mae: 36718092.0000 - val_loss: 6038293984575488.0000 - val_mae: 41217816.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4884258283847680.0000 - mae: 36677436.0000 - val_loss: 5959946801774592.0000 - val_mae: 40924356.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6305643350720512.0000 - mae: 39058416.0000 - val_loss: 5884555630215168.0000 - val_mae: 40656000.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6201614410973184.0000 - mae: 37348052.0000 - val_loss: 5816245249114112.0000 - val_mae: 40406900.0000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 65644902922321920.0000 - mae: 134773088.0000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 66331702552690688.0000 - mae: 135719232.0000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 5894096363192320.0000 - mae: 41787744.0000\n",
      "Model 1 - Loss: 6.056134527103795e+16, MAE: 126615272.0\n",
      "Model 2 - Loss: 6.12000584475607e+16, MAE: 127529224.0\n",
      "Model 3 - Loss: 5816245249114112.0, MAE: 40406900.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Modelo 1\n",
    "model1 = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model1.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Modelo 2\n",
    "model2 = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    Dense(64, activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Modelo 3\n",
    "model3 = Sequential([\n",
    "    Dense(256, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model3.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar los modelos\n",
    "history1 = model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "history2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "history3 = model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluar los modelos\n",
    "loss1, mae1 = model1.evaluate(X_test, y_test)\n",
    "loss2, mae2 = model2.evaluate(X_test, y_test)\n",
    "loss3, mae3 = model3.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Model 1 - Loss: {loss1}, MAE: {mae1}')\n",
    "print(f'Model 2 - Loss: {loss2}, MAE: {mae2}')\n",
    "print(f'Model 3 - Loss: {loss3}, MAE: {mae3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2109a-3869-490f-b3f7-b0267180b00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
